import re
import time
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple

import pandas as pd
import requests
import streamlit as st
from bs4 import BeautifulSoup
import tldextract


# -----------------------------
# Page Config
# -----------------------------
st.set_page_config(
    page_title="ì˜¤ëŠ˜ ì„¹ì…˜ë³„ Top 5 (êµ­ë‚´/í•´ì™¸)",
    page_icon="ğŸ—ï¸",
    layout="wide",
)

st.markdown(
    """
<style>
.block-container { padding-top: 1.1rem; padding-bottom: 2rem; }
small.muted { color: rgba(49,51,63,.65); }
.card {
  border: 1px solid rgba(49,51,63,.15);
  border-radius: 14px;
  padding: 14px 16px;
  margin-bottom: 10px;
  background: rgba(255,255,255,.02);
}
.card h4 { margin: 0 0 8px 0; }
.kv { display: flex; gap: 12px; flex-wrap: wrap; margin: 6px 0 10px 0; }
.kv span { font-size: 0.92rem; color: rgba(49,51,63,.72); }
.badge { display:inline-block; padding:2px 8px; border-radius: 999px; border:1px solid rgba(49,51,63,.18); font-size:.82rem;}
hr.soft { border: none; border-top: 1px solid rgba(49,51,63,.10); margin: 14px 0; }
</style>
""",
    unsafe_allow_html=True,
)

# -----------------------------
# Constants
# -----------------------------
KST = timezone(timedelta(hours=9))
UTC = timezone.utc

GDELT_DOC_ENDPOINT = "https://api.gdeltproject.org/api/v2/doc/doc"
USER_AGENT = "Mozilla/5.0 (compatible; StreamlitSectionTop5/1.0; +https://streamlit.io)"
REQUEST_TIMEOUT = 10  # seconds


# -----------------------------
# Models / Config
# -----------------------------
@dataclass(frozen=True)
class SectionQuery:
    section: str
    domestic_query: str
    overseas_query: str


SECTIONS: List[SectionQuery] = [
    SectionQuery(
        section="ì •ì¹˜",
        domestic_query='(ì •ì¹˜ OR ì •ë¶€ OR êµ­íšŒ OR ëŒ€í†µë ¹ OR ì—¬ë‹¹ OR ì•¼ë‹¹ OR ì´ì„  OR ëŒ€ì„  OR ì„ ê±° OR ê³µì²œ)',
        overseas_query='(politics OR government OR parliament OR congress OR president OR election OR campaign)',
    ),
    SectionQuery(
        section="ê²½ì œ",
        domestic_query='(ê²½ì œ OR ì¦ì‹œ OR ì£¼ì‹ OR ì½”ìŠ¤í”¼ OR ì½”ìŠ¤ë‹¥ OR í™˜ìœ¨ OR ê¸ˆë¦¬ OR ë¬¼ê°€ OR ì¸í”Œë ˆì´ì…˜ OR ê¸°ì—… OR ì‚°ì—… OR ë°˜ë„ì²´)',
        overseas_query='(economy OR markets OR stocks OR inflation OR interest rates OR central bank OR currency OR business OR industry OR semiconductor)',
    ),
    SectionQuery(
        section="ì‚¬íšŒ",
        domestic_query='(ì‚¬íšŒ OR ì‚¬ê±´ OR ì‚¬ê³  OR ë²”ì£„ OR ì¬ë‚œ OR êµìœ¡ OR ì˜ë£Œ OR ë³µì§€ OR ë…¸ë™ OR íŒŒì—… OR ë²•ì› OR ê²€ì°° OR ê²½ì°°)',
        overseas_query='(society OR crime OR accident OR disaster OR education OR health OR welfare OR labor OR strike OR court OR police)',
    ),
    SectionQuery(
        section="êµ­ì œ",
        domestic_query='(êµ­ì œ OR ì™¸êµ OR ì •ìƒíšŒë‹´ OR UN OR ìœ ì—” OR ë¯¸êµ­ OR ì¤‘êµ­ OR ì¼ë³¸ OR ëŸ¬ì‹œì•„ OR ìš°í¬ë¼ì´ë‚˜ OR ì¤‘ë™ OR ê°€ì)',
        overseas_query='(world OR international OR diplomacy OR summit OR UN OR Ukraine OR Russia OR China OR Japan OR Middle East OR Gaza)',
    ),
    SectionQuery(
        section="ìŠ¤í¬ì¸ ",
        domestic_query='(ìŠ¤í¬ì¸  OR ì¶•êµ¬ OR ì•¼êµ¬ OR ë†êµ¬ OR ë°°êµ¬ OR ê³¨í”„ OR eìŠ¤í¬ì¸  OR ì˜¬ë¦¼í”½ OR ì›”ë“œì»µ OR KBO OR Kë¦¬ê·¸)',
        overseas_query='(sports OR football OR soccer OR baseball OR basketball OR Olympics OR World Cup OR NBA OR MLB OR NHL)',
    ),
]


# -----------------------------
# Helpers
# -----------------------------
def clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip()


def normalize_domain(url: str) -> Optional[str]:
    if not url or not isinstance(url, str):
        return None
    try:
        ext = tldextract.extract(url)
        return ext.registered_domain.lower() if ext.registered_domain else None
    except Exception:
        return None


def parse_seendate_utc(s: str) -> Optional[datetime]:
    if not s or not isinstance(s, str):
        return None
    try:
        return datetime.strptime(s, "%Y%m%d%H%M%S").replace(tzinfo=UTC)
    except Exception:
        return None


def kst_today_range_utc() -> Tuple[datetime, datetime]:
    now_kst = datetime.now(KST)
    start_kst = now_kst.replace(hour=0, minute=0, second=0, microsecond=0)
    return start_kst.astimezone(UTC), now_kst.astimezone(UTC)


@st.cache_data(ttl=60 * 10, show_spinner=False)  # 10 minutes
def fetch_gdelt_articles(
    query: str,
    start_dt_utc: datetime,
    end_dt_utc: datetime,
    max_records: int,
) -> pd.DataFrame:
    def fmt(dt: datetime) -> str:
        return dt.astimezone(UTC).strftime("%Y%m%d%H%M%S")

    params = {
        "query": query,
        "mode": "ArtList",
        "format": "json",
        "maxrecords": int(max_records),
        "sort": "HybridRel",
        "startdatetime": fmt(start_dt_utc),
        "enddatetime": fmt(end_dt_utc),
    }

    headers = {"User-Agent": USER_AGENT}
    r = requests.get(GDELT_DOC_ENDPOINT, params=params, headers=headers, timeout=REQUEST_TIMEOUT)
    r.raise_for_status()
    data = r.json()

    rows = []
    for a in (data.get("articles", []) or []):
        url = a.get("url")
        rows.append(
            {
                "title": clean_text(a.get("title") or ""),
                "url": url,
                "seendate": a.get("seendate"),
                "published_utc": parse_seendate_utc(a.get("seendate")),
                "sourceCountry": a.get("sourceCountry"),
                "language": a.get("language"),
                "domain": normalize_domain(url) or "unknown",
            }
        )

    df = pd.DataFrame(rows)
    if df.empty:
        return df

    df["published_utc"] = pd.to_datetime(df["published_utc"], utc=True, errors="coerce")
    df = df.dropna(subset=["published_utc"])
    df = df[df["title"] != ""]
    df = df.drop_duplicates(subset=["url"], keep="first")
    return df


@st.cache_data(ttl=60 * 60, show_spinner=False)  # 1 hour
def fetch_meta_description(url: str) -> Optional[str]:
    if not url:
        return None
    headers = {
        "User-Agent": USER_AGENT,
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
    }
    try:
        r = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
        if r.status_code >= 400:
            return None
        soup = BeautifulSoup(r.text, "lxml")

        og = soup.find("meta", property="og:description")
        if og and og.get("content"):
            return clean_text(og.get("content"))

        meta = soup.find("meta", attrs={"name": "description"})
        if meta and meta.get("content"):
            return clean_text(meta.get("content"))

        p = soup.find("p")
        if p and p.get_text(strip=True):
            return clean_text(p.get_text(strip=True))[:260]

        return None
    except Exception:
        return None


def build_section_query(region: str, section_cfg: SectionQuery, extra_keyword: str) -> str:
    """
    - êµ­ë‚´: sourceCountry:KOR + í•œêµ­ì–´ ì„¹ì…˜ í‚¤ì›Œë“œ (+ optional extra keyword)
    - í•´ì™¸: language:eng -sourceCountry:KOR + ì˜ì–´ ì„¹ì…˜ í‚¤ì›Œë“œ (+ optional extra keyword)
    """
    extra = clean_text(extra_keyword)
    extra_part = f'("{extra}")' if extra else ""

    if region == "êµ­ë‚´":
        base = "sourceCountry:KOR"
        sec = section_cfg.domestic_query
        return f"{base} {sec} {extra_part}".strip()

    base = "language:eng -sourceCountry:KOR"
    sec = section_cfg.overseas_query
    return f"{base} {sec} {extra_part}".strip()


def rank_and_pick_top(df: pd.DataFrame, top_n: int) -> pd.DataFrame:
    """
    GDELT HybridRel ê¸°ë°˜ ë°˜í™˜ì„ ë°›ë˜, í™”ë©´ì—ì„œëŠ” ìµœì‹ ì„±ì„ ì¡°ê¸ˆ ë” ë°˜ì˜.
    """
    if df.empty:
        return df
    df = df.copy()
    df = df.sort_values("published_utc", ascending=False)
    return df.head(top_n)


def render_top_list(section_name: str, top_df: pd.DataFrame, enable_summary: bool):
    st.subheader(f"{section_name} Â· Top {len(top_df)}")
    if top_df.empty:
        st.warning("í•´ë‹¹ ì„¹ì…˜ì—ì„œ ì˜¤ëŠ˜ ê¸°ì‚¬ í›„ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (í‚¤ì›Œë“œ/ë²”ìœ„ ì¡°ì • í•„ìš”)")
        return

    for idx, row in top_df.reset_index(drop=True).iterrows():
        title = row.get("title") or "(ì œëª© ì—†ìŒ)"
        url = row.get("url") or ""
        domain = row.get("domain") or "unknown"
        pub_kst = row.get("published_utc").tz_convert(KST) if hasattr(row.get("published_utc"), "tz_convert") else None
        pub_str = pub_kst.strftime("%H:%M (KST)") if pub_kst is not None else ""

        summary = row.get("summary") or ""

        st.markdown(
            f"""
<div class="card">
  <div class="kv">
    <span class="badge">#{idx+1}</span>
    <span>ë„ë©”ì¸: <b>{domain}</b></span>
    <span>ë°œí–‰: <b>{pub_str}</b></span>
  </div>
  <h4>{title}</h4>
  <div>
    <a href="{url}" target="_blank" rel="noopener noreferrer">{url}</a>
  </div>
  <hr class="soft"/>
  <div>
    <b>í•µì‹¬ ìš”ì•½</b><br/>
    {"<small class='muted'>ìš”ì•½ ê¸°ëŠ¥ì´ êº¼ì ¸ ìˆìŠµë‹ˆë‹¤.</small>" if not enable_summary else (
        "<small class='muted'>ìš”ì•½ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤(ì‚¬ì´íŠ¸ ì°¨ë‹¨/ë©”íƒ€ì •ë³´ ë¶€ì¬ ê°€ëŠ¥).</small>" if not summary else summary
    )}
  </div>
</div>
""",
            unsafe_allow_html=True,
        )


# -----------------------------
# UI
# -----------------------------
st.title("ì˜¤ëŠ˜ ì„¹ì…˜ë³„ ì£¼ìš” ë‰´ìŠ¤ Top 5")
st.caption("êµ­ë‚´/í•´ì™¸ ì„ íƒ í›„, ì„¹ì…˜ë³„(ì •ì¹˜Â·ê²½ì œÂ·ì‚¬íšŒÂ·êµ­ì œÂ·ìŠ¤í¬ì¸ )ë¡œ ì˜¤ëŠ˜ Top 5ë¥¼ ìš”ì•½ ì •ë¦¬í•©ë‹ˆë‹¤. (ë°ì´í„°: GDELT)")

with st.sidebar:
    st.header("1) ë²”ìœ„ ì„ íƒ")
    region = st.radio("êµ­ë‚´/í•´ì™¸", options=["êµ­ë‚´", "í•´ì™¸"], horizontal=True)

    st.divider()
    st.header("2) ì„¹ì…˜ ì„ íƒ")
    section_names = [s.section for s in SECTIONS]
    selected_sections = st.multiselect(
        "ë¶„ì„í•  ì„¹ì…˜(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
        options=section_names,
        default=section_names,  # ê¸°ë³¸: ì „ì²´ ì„¹ì…˜
    )

    st.markdown(
        '<small class="muted">ì„¹ì…˜ì€ GDELTì— â€œí¸ì§‘êµ­ ì„¹ì…˜â€ì´ ì§ì ‘ ì œê³µë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì„¹ì…˜ë³„ ëŒ€í‘œ í‚¤ì›Œë“œ ì¿¼ë¦¬ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.</small>',
        unsafe_allow_html=True,
    )

    st.divider()
    st.header("3) Top ë‰´ìŠ¤ êµ¬ì„±")
    extra_keyword = st.text_input(
        "ì¶”ê°€ í‚¤ì›Œë“œ(ì„ íƒ)",
        value="",
        help="ì˜ˆ: â€˜íƒ„ì†Œì„¸â€™, â€˜ì² ê°•â€™, â€˜ì›ì „â€™ ë“±ì„ ë„£ìœ¼ë©´ í•´ë‹¹ ì´ìŠˆ ì¤‘ì‹¬ìœ¼ë¡œ ì„¹ì…˜ë³„ Top 5ê°€ êµ¬ì„±ë©ë‹ˆë‹¤.",
    )

    top_n = st.number_input("ì„¹ì…˜ë³„ Top N", min_value=3, max_value=10, value=5, step=1)

    candidate_pool = st.number_input(
        "ì„¹ì…˜ë³„ í›„ë³´ ê¸°ì‚¬ ìˆ˜(ìˆ˜ì§‘ëŸ‰)",
        min_value=50,
        max_value=400,
        value=180,
        step=10,
        help="ê° ì„¹ì…˜ì—ì„œ Top Nì„ ë½‘ê¸° ì „ GDELTì—ì„œ ê°€ì ¸ì˜¤ëŠ” í›„ë³´ ê¸°ì‚¬ ìˆ˜ì…ë‹ˆë‹¤.",
    )

    enable_summary = st.toggle(
        "ê¸°ì‚¬ í•µì‹¬ìš”ì•½(ë©”íƒ€ë””ìŠ¤í¬ë¦½ì…˜) ê°€ì ¸ì˜¤ê¸°",
        value=True,
        help="ì‚¬ì´íŠ¸ ì°¨ë‹¨/ì†ë„ ì €í•˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë„ë©´ íƒ€ì´í‹€ ì¤‘ì‹¬ìœ¼ë¡œë§Œ í‘œì‹œí•©ë‹ˆë‹¤.",
    )

    run = st.button("ì˜¤ëŠ˜ ì„¹ì…˜ë³„ Top ë‰´ìŠ¤ ìƒì„±", type="primary", use_container_width=True)

if not run:
    st.info("ì¢Œì¸¡ì—ì„œ ë²”ìœ„ì™€ ì„¹ì…˜ì„ ì„ íƒí•œ ë’¤, â€˜ì˜¤ëŠ˜ ì„¹ì…˜ë³„ Top ë‰´ìŠ¤ ìƒì„±â€™ì„ ëˆŒëŸ¬ ì£¼ì„¸ìš”.")
    st.stop()

if not selected_sections:
    st.warning("ìµœì†Œ 1ê°œ ì„¹ì…˜ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    st.stop()

start_utc, end_utc = kst_today_range_utc()
today_kst = datetime.now(KST).strftime("%Y-%m-%d")

st.markdown(f"### {today_kst} Â· {region} Â· ì„¹ì…˜ë³„ Top {int(top_n)}")
st.caption("ìˆ˜ì§‘ ê¸°ê°„: ì˜¤ëŠ˜ 00:00 ~ í˜„ì¬ (KST)")

# Build a quick lookup for section configs
section_cfg_map: Dict[str, SectionQuery] = {s.section: s for s in SECTIONS}

results: Dict[str, pd.DataFrame] = {}

with st.spinner("ì„¹ì…˜ë³„ ê¸°ì‚¬ í›„ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
    for sec_name in selected_sections:
        cfg = section_cfg_map[sec_name]
        q = build_section_query(region, cfg, extra_keyword)

        try:
            df = fetch_gdelt_articles(
                query=q,
                start_dt_utc=start_utc,
                end_dt_utc=end_utc,
                max_records=int(candidate_pool),
            )
        except requests.HTTPError as e:
            st.error(f"[{sec_name}] GDELT ìš”ì²­ ì‹¤íŒ¨(HTTPError): {e}")
            df = pd.DataFrame()
        except Exception as e:
            st.error(f"[{sec_name}] GDELT ìš”ì²­ ì‹¤íŒ¨: {e}")
            df = pd.DataFrame()

        # (êµ­ë‚´) ì•ˆì „ì¥ì¹˜: sourceCountry=KORë§Œ ìœ ì§€
        if region == "êµ­ë‚´" and not df.empty:
            df = df[df["sourceCountry"].fillna("").str.upper() == "KOR"]

        top_df = rank_and_pick_top(df, int(top_n))

        # Summaries (optional) - only for selected top rows
        if enable_summary and not top_df.empty:
            top_df = top_df.copy()
            top_df["summary"] = ""
            for i in range(len(top_df)):
                url = top_df.iloc[i]["url"]
                time.sleep(0.12)  # polite delay
                top_df.iat[i, top_df.columns.get_loc("summary")] = fetch_meta_description(url) or ""

        results[sec_name] = top_df

# Render: tabs per section
tabs = st.tabs(selected_sections)
for tab, sec_name in zip(tabs, selected_sections):
    with tab:
        # show query diagnostics
        cfg = section_cfg_map[sec_name]
        q = build_section_query(region, cfg, extra_keyword)
        st.markdown(f"<small class='muted'>ì‚¬ìš© ì¿¼ë¦¬: {clean_text(q)}</small>", unsafe_allow_html=True)

        render_top_list(sec_name, results.get(sec_name, pd.DataFrame()), enable_summary)

st.caption(
    "ì£¼ì˜: â€˜Topâ€™ì€ GDELT ìˆ˜ì§‘/ì •ë ¬(HybridRel)ê³¼ ìµœì‹ ì„± ê¸°ì¤€ì˜ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì„ ì •ëœ ëŒ€í‘œ ê¸°ì‚¬ì…ë‹ˆë‹¤. "
    "í¬í„¸/í¸ì§‘êµ­ì˜ â€˜ë©”ì¸ Topâ€™ê³¼ ì™„ì „íˆ ë™ì¼í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)
